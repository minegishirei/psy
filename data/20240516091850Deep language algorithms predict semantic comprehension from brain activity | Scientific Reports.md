[:contents]参考 : https://www.nature.com/articles/s41598-022-20460-9


Deep language algorithms predict semantic comprehension from brain activity | Scientific Reports





















































































































































































[メインコンテンツにスキップします](#content)


Nature.comにアクセスしていただきありがとうございます。CSSのサポートが限られているブラウザバージョンを使用しています。取得する
 最高のエクスペリエンス、最新のブラウザを使用することをお勧めします（または互換性モードをオフにします
 インターネットエクスプローラ）。それまでの間、継続的なサポートを確保するために、スタイルなしでサイトを表示しています
 とjavascript。








広告




[[error]](//pubads.g.doubleclick.net/gampad/jump?iu=/285/scientific_reports/article&sz=728x90&c=-1963493011&t=pos%3Dtop%26type%3Darticle%26artid%3Ds41598-022-20460-9%26doi%3D10.1038/s41598-022-20460-9%26subjmeta%3D117,1594,2649,378,631,639,705%26kwrd%3DComputer+science,Language)










[[error]](/srep)

* すべてのジャーナルを表示します
* 検索
* ログイン








* コンテンツを探索します
* ジャーナルについて
* 私たちと一緒に公開してください


* アラートにサインアップします
* RSSフィード








1. 自然
2. 科学レポート
3. 記事
4. 記事










 Deep language algorithms predict semantic comprehension from brain activity
 

[PDFをダウンロードします](/articles/s41598-022-20460-9.pdf)







[PDFをダウンロードします](/articles/s41598-022-20460-9.pdf)





* 記事
* オープンアクセス
* 公開：2022年9月29日


ディープ言語アルゴリズムは、脳の活動からの意味的理解を予測します
================================


* Charlotte Caucheteux1.2、
* Alexandre Gramfort2＆
* ジャン・レミ・キング1.3


科学レポート
第12巻、記事番号：16327（2022）
 この記事を引用してください



* 20Kアクセス
* 19の引用
* 131 altmetric
* メトリックの詳細





### 科目


* コンピュータサイエンス
* 言語





抽象的な
----

GPT-2のような深い言語アルゴリズムは、テキストを処理する顕著な能力を実証しており、現在、自動翻訳、要約、対話のバックボーンを構成しています。ただし、これらのモデルが人間の理解に関連する情報をエンコードするかどうかは、まだ議論の余地があります。ここでは、GPT-2の表現が話し言葉に対する脳の反応をマッピングするだけでなく、被験者が対応する物語を理解する程度も予測することを示します。この目的のために、70分間の短編小説を聴きながら、機能的な磁気共鳴画像で記録された101人の被験者を分析します。次に、線形マッピングモデルを適合して、GPT-2の活性化から脳の活動を予測します。最後に、このマッピングが確実に相関していることを示します（\（\ mathcal {r} = 0.50、p <^{-15} \））は、各ストーリーで評価される被験者の理解スコアとこの効果は、角度、内側側頭、および上顎のgyriにピークに達し、GPT-2の深層で生成された長距離依存関係によって最もよく説明されています。全体として、この研究は、言語の理解の根底にある脳の計算を明確にするのに深い言語モデルがどのように役立つかを示しています。





### 同様のコンテンツは他の人によって表示されます





![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs42256-024-00832-8/MediaObjects/42256_2024_832_Fig1_HTML.png)



### 化学ツールを使用して大規模な言語モデルを増強します



Article
Open access
08 May 2024






![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41593-024-01626-2/MediaObjects/41593_2024_1626_Fig1_HTML.png)



### スライステンソルコンポーネント分析を伴う神経サブスペースを超えた寸法削減



Article
Open access
06 May 2024






![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs44159-024-00300-5/MediaObjects/44159_2024_300_Fig1_HTML.png)



### 人間の因果学習と推論の発展



Article
26 April 2024








2年も経たないうちに、GPT-2のような言語変圧器は、自然言語処理の分野（NLP）に革命をもたらしました。これらの深い学習アーキテクチャは、通常、非常に大きなコーパスで訓練され、部分的にマスクされたテキストを完成させ、翻訳、要約、および質問を回答するタスク1,2,3の1つの適合ソリューションを提供します。これらの進歩は大きな疑問を提起します：これらのアルゴリズムは人間の脳のような言語を処理しますか？最近の研究は、それらが部分的に行うことを示唆しています。さまざまな深い神経ネットワークの隠された表現は、単一サンプルを予測することが示されています。書かれたテキスト6,12。

ただし、これらのモデルは、一般的な行動に特に関連する情報にエンコード、取得、および特に理解に関連する情報に注意を払うかどうかに注意してください。この問題は、被験者と動詞の合意14,15,17、因果的推論16,19、ストーリー生成、テキストの要約、対話と質問の回答20など、深い言語モデルの動作が複雑な質問によって挑戦されたままであることにすべて関連しています20、21,22,23,24。

理解とGPT-2の表現との関係を調査するために、70分の7つの短編を聞いている101人の被験者の機能的磁気共鳴画像法とGPT-2の活性化を比較します。最初に、この類似性を「脳スコア」（m）25,26で定量化します。次に、各ストーリーの最後にアンケートによって個別に評価されるように、脳のスコアがセマンティック理解とともに体系的に変化するか、したがって予測する方法を評価します。最後に、GPT-2のプロセスを分解して操作することにより、（1）脳領域、（2）表現のレベル（音韻、語彙、組成）、および（3）この予測に特に関連する注意ゲーティングを特定します。

行動、脳の活性化、およびGPT-2の表現との間に特定されたアライメントは、理解が特定の計算階層に依存していることを示唆しています。ウィンドウズ。



**Figure 1**

[[error]](/articles/s41598-022-20460-9/figures/1)脳のスコアと理解との相関。（a）101人の被験者が物語（合計70分間の一意のオーディオ刺激）を聴き、脳信号は機能的なMRIを使用して記録されます。各ストーリーの最後に、各被験者にアンケートが提出されて理解を評価し、回答はそれぞれ（物語、主題）ペア（灰色のボックス）に固有の理解スコアに要約されます。並行して（左側の青いボックス）、被験者の脳の活性化とGPT-2の活性化との間のマッピングを測定します。この目的のために、GPT-2活性化xを入力として与えられた場合、1つのボクセルyの脳活動を予測するために、線形の時空間モデル（\（f \ circ g \））が適合します。「脳スコア」と呼ばれるマッピングの程度は、各ボクセルに対して、予測されたデータと実際の脳活動の間のピアソン相関（青方程式、メソッドを参照）として定義されます。最後に、ピアソンの相関（赤方程式）を使用して、被験者の理解スコアと対応する脳スコアとの相関関係をテストします。正の相関は、脳全体で共有される表現とGPT-2が被験者が物語を理解するための鍵であることを意味します。（b）GPT-2の8層の活性化の脳スコア（fMRI予測可能性）。スコアは、脳領域内の被験者、物語、およびボクセル全体で平均化されます（各半球の142領域、Destroiex Atlas27の下位区分に続いて、補足情報a）。双方向ウィルコクソンテスト（被験者、物語）のペア全体で評価されるように、重要な領域のみが表示され、脳スコアがゼロとは大幅に異なるかどうかをテストします（しきい値：0.05）。（c）異なる活性化空間について、fMRIボクセル全体で平均化された脳スコア：音韻的特徴（単語レート、音素、音素、トーン、ストレス、緑）、GPT-2の非透過化された単語埋め込み（「単語」、ライトブルー）およびGPT-2のコンテキスト化された層の活性化（レイヤー1から12層まで、青）。エラーバーは、（サブジェクト、ナラティブ）ペア（n = 237）にわたる平均の標準誤差を指します。（d）それぞれ（主題、物語）ペアに対して、ボクセル全体で平均化された理解とGPT-2脳スコア。赤では、ピアソンの2つの間の相関（\（\ mathcal {r} \））、対応する回帰ラインと回帰係数の95％信頼区間。（e）理解の領域での理解と脳スコアの間の相関（\（\ mathcal {r} \））。脳スコアは、最初に脳領域内のボクセル全体で平均化され（Bと同様）、被験者の理解スコアと相関します。有意な相関のみが表示されます（しきい値：0.05）。（f）理解と音韻特徴（M（音素）（i）による被験者の脳マッピングとの間の相関スコア（\（\ mathcal {r} \））、音韻が説明されていない単語埋め込みマッピングの共有特徴\（\ mathcal {m}（\ mathrm {word}） - \ mathcal {m mathrm {phonemic}）\）（ii）とGPT-2層のマッピングのシェアは、単語によって考慮されていません - 埋め込み\（\ mathcal {m}（\ mathrm {gpt2}） - \ mathcal {m}（\ mathrm {word}）\）（（g）対象領域あたり（bに類似）、および左半球の範囲と同様の理解との対応する相関（\ mathcal {r} \）。e）黒で、脳と相関スコアの上位10領域（d）、（e）、および（f）の補足情報を参照してください。scipy28によって提供されます（b）、（e）、および（f）、p値は、2 \（\ times \）142の対象領域にわたって誤検出率（ベンジャミン/hochberg）を使用して修正されます。

[フルサイズの画像](/articles/s41598-022-20460-9/figures/1)

**Figure 2**

[[error]](/articles/s41598-022-20460-9/figures/2)GPT-2の注意範囲が脳のスコアと理解スコアに与える影響。（a）ヒートマップは、注意スパン（「距離」）と層の関数として、平均（被験者、ストーリー、ボクセル、ボクセル間）の脳スコアを表示します。一番上の行には、各注意スパンのレイヤー係数が表示されます（被験者、ストーリー、ボクセル全体で平均化されています）。右の線には、各レイヤーの距離係数が表示されます（被写体、ストーリー、ボクセル全体で平均化されます）。エラーバーは、サブジェクトストーリーペア全体の平均（SEM）の標準誤差に対応しています。（b）各脳領域の距離係数（被験者とストーリー全体で平均）。統計的有意性は、被験者の階段のペア全体でウィルコクソンテストで評価されます。（c）各脳領域の層係数（被験者とストーリー全体で平均）。（d） - （f）（a） - （c）と同様ですが、レイヤー（および距離）係数は、層（または距離）と理解スコアの関係を評価するようになりました。統計的有意性は、1000のサブサンプルのサブジェクトストーリーペアを持つブートストラップ手順を使用して評価されます。エラーバーは、サブサンプル間の標準偏差です。すべての脳マップの場合、有意な値のみが表示されます（\（p <0.05 \）脳領域全体のFDR補正後）。

[フルサイズの画像](/articles/s41598-022-20460-9/figures/2)結果
--

### GPT-2のアクティベーションは、話された物語へのfMRI応答に直線的にマッピングされます

GPT-2が脳の表現と同様の表現を生成するかどうかを評価するために、物語データセットを分析します。101人の被験者は、脳の活動がfMRIで記録されている間に7つの短編を聞いています。被験者は必ずしも同じ話を聞くとは限らないことに注意してください（図3）。最初に、fMRI応答をGPT-2の活性化の線形組み合わせから予測できるかどうか、各ボクセル、主題、物語について独立して評価します（図1A）。このマッピングの脳スコアを使用したこのマッピングの精度\（\ mathcal {m} \）：すなわち、真のfMRI応答と、同じ物語に対するGPT-2の応答からの相互検証と直線的に予測されたfMRI応答との相関を要約します。（メソッドを参照）。

fMRIの空間分解能と多重比較のためにボクセル分析を修正する必要性を軽減するために、ここでは、1）ボクセル全体の平均脳スコアまたは2）各領域内の平均スコア（\（n = 314 \）のいずれか）のいずれかを報告します。Destureux Atlas27の自動下位区分、補足情報a）、および脳領域全体の複数の比較のための統計テストを修正した後。以前の発見5,7,29,30と一致して、これらの脳スコアは分散型および両側皮質ネットワークで有意であり、中間および上半身のgyriおよび硫黄、および上筋骨およびインファロ前腹部でのピークcortex5,7,29（図1b）。

GPT-2の各層の活性化を個別に分析することにより、以前に報告された5,7,29のように、中間層が脳に最適なマップ（図1C）を確認します。明確にするために、次の分析は、8層から抽出された活性化、つまりボクセル全体で平均して脳スコアが最も高い層に焦点を当てています（図1C）。ただし、結果はGPT-2の他のコンテキスト層に一般化されます（補足情報E、補足図S4）。

### GPT-2の脳の予測は、意味理解と相関しています

GPT-2と脳の間の線形マッピングは、幸運な対応を反映していますか？それとも、それどころか、それは高レベルのセマンティクスの同様の表現を反映しています8？この問題に対処するために、これらの脳のスコアを被験者の理解レベルと相関させ、各ストーリーの最後にアンケートで各被験者と階段のペアについて評価されます。すべてのボクセルで平均して、脳のスコアと理解度の間の相関は\（\ mathcal {r} = 0.50 \）（\（p <10^{-15} \）、図1dに到達します。SCIPY28が提供するピアソンのテストで）。この相関は、言語処理に通常関連するさまざまな両側側頭、頭頂、前頭前野の皮質にわたって重要です（図1E）。一緒に、これらの結果は、GPT-2と脳の間の共有表現がセマンティック理解によって確実に異なることを示唆しています。

### 低レベルの処理は、理解とGPT-2のマッピングとの相関関係を部分的に説明します

低レベルの音声表現は通常、注意31,32によって異なるため、ダウンストリームの理解プロセスに影響を与える可能性があります。その結果、理解とGPT-2の脳マッピングとの相関関係が、単に低レベルの聴覚処理の変動によって単純に駆動されるのかと合法的に疑問に思うことができます。この問題に対処するために、低レベルの音韻的特徴を与えられたfMRIの予測可能性を評価します：単語レート、音素速度、音素、ストレス、物語のトーン（メソッドを参照）。対応する脳スコアは、被験者の理解（\（\ mathcal {r} = 0.17、p <10^{-2} \））と相関していますが、GPT-2の脳スコアよりもかなり少ない（\（\ delta \ mathcal{r} = 0.32 \））。これらの低レベルの相関と、左の上側頭皮質の理解の補足（図1F）。全体として、この結果は、理解とGPT-2の脳マッピングの間のリンクが、低レベルの聴覚処理のバリエーションによって部分的に説明される可能性があることを示唆しています。

### 高レベルの表現は、理解を最もよく予測します

理解とGPT-2のマッピングとの相関関係は、語彙プロセスおよび/または単語を有意義に組み合わせる能力によって駆動されますか？この問題に取り組むために、GPT-2の単語埋め込み（すなわち、レイヤー0）から得られた相関をGPT-2の8層から得た相関、つまりコンテキスト埋め込みと比較します。ボクセル全体で平均して、理解との相関は、GPT-2の埋め込みでは、その文脈的埋め込みよりも0.12低くなっています。単語の埋め込みと音韻の特徴を比較する類似の分析を図1Fに示します。上側葉およびPARS三角形の厳密に語彙的効果（単語埋め込みと音韻論）のピーク。対照的に、高レベルの効果（GPT-2 8層対ワード埋め込み）のピーク上、前頭前部および下部前頭回の三角形および手術部分の両方で、上部前部の上側旋門のピーク - ネットワーク通常、高レベルの言語理解に関連しています7,33,34,35,36,37。一緒に、これらのモデルの比較は、GPT-2が音声に対する脳の反応が理解によってどのように異なるかを最もよく予測することを示唆しています。

### 理解効果は、主に個人のばらつきによって駆動されます

理解スコアの変動性は、外ゼナス因子（たとえば、GPT-2の他のストーリーよりも理解するのが難しい場合がある）および/または内在的な要因（例えば、一部の被験者が事前の知識のために特定のテキストをよりよく理解することができる場合）から生じる可能性があります。この問題に対処するために、線形混合モデルを適合させて、脳スコアを与えられた理解スコアを予測し、物語をランダム効果として指定します（補足情報bを参照）。脳スコアの固定効果（物語間で共有）は非常に重要です：\（\ beta = \、0.04、p <10^{-29} \）、cf。補足情報b）。ただし、ランダム効果（各単一の物語に固有の勾配）は（\（\ beta <10^{-2} \）、\（p> \、0.11 \））ではありません。また、各単一の物語内のメイン分析（図1D）を再現します。理解との相関は「シャーロック」ストーリーで0.76に達し、すべてのストーリーで0.40を超えています（補足情報cを参照）。全体として、これらの分析では、GPT-2とセマンティック理解の間のリンクが、内在性要因、つまり理解スコアの個人差によって最もよく説明されることを確認しています。

### 脳領域の分解、表現のレベル、および理解の根底にある注意距離

GPT-2をさらに分解して、（i）人間の脳とマッピングし、（ii）被験者の理解を予測する表現を生成するメカニズムを特定できますか？この問題に対処するために、（1）短距離と長距離の注意ゲーティング、（2）表現の深さ、（3）脳と理解のスコアの間のリンクを調査します。具体的には、これらのスコアの両方を異なるGPT-2レイヤーKに対して計算します。注意スパンを異なる距離dに制限する場合（つまり、層\（k '\ le k \）、前の単語にのみアクセスします）。体系的かつ独立してkとdを変化させることにより、\（\ beta \_ {\ mathrm {distant}} \）および\（\ beta \_ {\ mathrm {layer}} \）を計算できます。理解度は、それぞれレイヤーと注意スパンによって異なります。正確には、正の\（\ beta \_ {\ mathrm {distant}} \）は、スコアが長距離依存関係に敏感であることを示します。それどころか、null \（\ beta \_ {\ mathrm {distant}} \）は、スコアが長距離依存関係に敏感ではないことを示します。同様に、正の\（\ beta \_ {\ mathrm {layer}} \）は、深い層が浅い層よりも優れたスコアを持っているのに対し、負の\（\ beta \_ {\ mathrm {layer}} \）がその浅い層を示していることを示しています。ディープレイヤーよりも優れたスコアを持っています。

私たちの結果は3つあります。まず、脳スコア（\（\ mathcal {m} \））と理解スコア（\（\ mathcal {r} \））の両方が注意スパン（\（\ beta \_ {\ mathrm {distant}}）とともに増加します。> 0 \）、\（p^{m} <10^{-14} \）脳スコアの場合、\（p^{r} = \、0.01 \）、および理解スコアの場合）表現（\（\ beta \_ {\ mathrm {layer}}> 0 \）、\（p^{m} <10^{-4} \）、\（p^{r} = \、0.001 \）））。遠いコンテキストに注意を払って得られたスコアのゲインは、最も遠いアイテム（例：距離\（\約1000 \）の間）と300ワードまでの間でも観察されます：\（\ delta r> \、0 \）、\（p^{m} <10^{-4} \）、\（p^{r} = \、0.02 \）、図2a）。

第二に、注意スパンは主に脳のスコアと中間層の理解スコアに影響を与えます（レイヤー8とレイヤー12の差：\（\ delta \ beta \_ {\ mathrm {distance}} = \、0.001 \）、\（（）p^{m} <10^{ - 8} \）脳スコアの場合、\（\ delta \ beta \_ {\ mathrm {distant}} = \、0.03 \）、\（p^{r} = \、0.005\）理解スコアの場合、図2AD）。興味深いことに、驚いたことに、最初のレイヤーの注意範囲を制限すると、理解を予測する能力が向上しました（例：最初のレイヤーでは、10語の注意と完全な注意を払ったスコアの違い\（\ delta r = \、0.06 \）、\（p = \、0.004 \）、図2d）。この予期しない結果は、深さの関数として注意力を高めることにより、言語変圧器を脳により類似することができることを示唆しています。

最後に、高レベルの理解に一般的に関連する脳領域は、ネットワークの深い文脈的表現によってよりよく予測され、それらの対応する脳スコアと理解スコアは、長距離の注意によって比較的強く変調されます（例：角度：\（\）beta \_ {\ mathrm {layer}} = 0.14> 0 \）、\（p = \、0.002 \）、\（\ beta \_ {\ mathrm {distance}} = \、0.03> 0 \）、\（p（（p）= \、0.016 \）理解スコアの場合）。それどころか、低レベルの音響領域は、ネットワークの浅い層によって最もよく予測されており、それに比べて、長距離依存性によってほとんど変化しません（たとえば、ヘシルジャイラスの理解スコアの場合\（\ beta \_ {\mathrm {layer}} = \、 - 0.076 <0 \）、\（p = \、0.004 \）、\（\ beta \_ {\ mathrm {distance}} = \、 - 0.014 <0 \）、\（p（p（p）= \、0.012 \））。

全体として、私たちの分析は、理解が神経表現の階層に依存していることを示唆しています。これにより、言語ネットワークの最初の領域は浅くて短期の注意プロセスを展開し、前頭心道ネットワークは組成および長期の注意プロセスに依存しています。興味深いことに、私たちの分析は、下層の注意力を短くすると脳のようになり、おそらくこれらのアルゴリズムに有用な帰納的バイアスを提供できることも強調しています。

議論
--

私たちの分析は、ストーリーの理解と、GPT-2のような言語変圧器が対応するストーリーに対する脳の反応にマッピングする程度との間に信頼できる相関関係を明らかにしています。さらに、このような言語モデルの体系的な比較、分解、操作により、（1）脳領域（2）表現レベル（軟化膜、語彙、上向き）を分解することができます。複雑な物語の理解に関連する過去の刺激の短いまたは長距離の検索。

これらの発見は、3つの主要な方法で理解の脳基盤に関する以前の研究を補完します。第一に、多くの定性的理論は、単語を意味のある表現にどのように組み合わせるかを説明しています36,37,38,39,40,41,42,43。たとえば、メモリ、統一、および制御モデル（MUC）は、3つのタイプの計算を区別し、それらをそれぞれ側頭葉、ブロカ領域、その他の前頭前葉にリンクします。同様に、拡張された引数依存性モデル（EADM）は、聴覚経路の腹側と背側の流れがそれぞれ時間非依存性と時間依存の統合を計算することを提案しています。私たちの結果は、言語領域の音響、語彙、組成の表現の類似の分割をサポートしています。ただし、聴覚皮質の周りに位置する言語ネットワークの初期領域は、わずかに異なる機能的解剖学を明らかにし、短い注意スパンのおかげで軟骨下および浅い表現を展開します。対照的に、前頭 - 頭頂ネットワークは、非常に遠いコンテキストを現在の単語と統合し、統合します（図1F）。これらの皮質領域が海馬と通信し、長期的な記憶から単語を回収する方法は、将来の研究のエキサイティングな方向性のままです44。

第二に、被験者間相関（例：33,35,45）に基づく「モデルフリー」メソッドまたは単語Vectors46に基づく「モデルベースの」メソッドのいずれかを使用して、理解を調査するためにいくつかの定量的アプローチが提案されています。たとえば、Lerner et al。通常のテキストまたはテキストを聞いている被験者のfMRIアクティビティを分析しました。脳の活動は、入力がひどくスクランブルされていた（したがって理解できない）場合でも、原発性および二次聴覚領域の被験者間で相関していますが、文と傍がスクランブルされていない場合にのみ、両側のインファロフロンタルおよび側頭頭頂皮質は被験者間でのみ相関していました。（したがって、理解できます）。Broderick et al。同様の設計を使用して、同じストーリー46のさまざまなスクランブルバージョンに対する脳波（EEG）応答と、逆およびノイズでプレイされた音声に対するEEG応答を調査しました47。私たちの結果と一貫して、彼らは、単語の埋め込みとEEG活動の間のマッピングが、これらのさまざまなプロトコルによって操作されるように理解によって異なることを示しました。したがって、（1）GPT-2の予測が被験者の理解によって異なる脳領域、および（2）これらの特徴がどのような表現に関連するかを示すことにより、これらの発見を補完します。言語ネットワークの最初の領域は、浅いスパンと攻撃のプロセスを展開しますが、前頭頭頂部のネットワークは構成および長期の出席プロセスに依存しています。

最後に、以前の分析では、脳5,48,49における注意の役割を調査しました。非常に長い用語の注意が脳のスコア（1,000語以上）に影響することを示し、（2）長い対立スパンに敏感な脳領域を識別すること、および（3）相互作用の調査の調査により、これらの研究を補完します。注意スパン、脳のような表現を生成する能力、および1つの行動指標の間：理解。

興味深いことに、角度角や上甲板のような一部の領域は、ささやかな脳スコアを提示し、それでも理解を強く予測しています。そのような解釈をどのように解釈できますか？深いニューラルネットワークは、低レベルの表現から高レベルの表現まで、さまざまな機能をエンコードすることを提案します。これらの機能のいくつかは、一般的な言語処理（例：単語に関する短距離情報）に関連する場合がありますが、他の機能は、理解に特に関連し、したがって理解を予測する場合があります（例：長距離依存関係）。この見解では、GPT-2の表現（例えば、ヘシェルの瞬間）によって最もよく予測される領域は、理解を最もよく予測するもの（例：Angular Gyrus）と同一である必要はありません。私たちのアブレーション研究はこの仮説に適合します。聴覚皮質は、脳スコアが高いが、理解度スコアが低いことでマークされており（図1G）、実際には短距離と浅い表現をコードするように見えます。（図2）。対照的に、角角は高い理解スコアを示し（図1G）、実際に長距離依存関係と深い表現をコードしているように見えます。2）。

全体として、本研究は、GPT-2が人間の理解に関連する情報を取得し、深い言語モデルと脳の類似性を研究する以前の作品を強化することを示唆しています。たとえば、いくつかの研究は、深いネットのエンコード精度が、アクティベーションのセマンティックおよび構文情報のレベルと、Context6,7から単語を予測する能力と相関することを示しました。これらの結果を補完し、GPT-2のエンコーディング精度が、理解アンケートで評価されているように、被験者の理解レベルと相関することを示します。興味深いことに、私たちの分析は、下層の注意範囲を短縮することで、それらをより脳のようにすることを強調しています。したがって、これらの結果は、脳と言語モデルの間の残りの機能的な違いを明らかにすることに貢献しているため、最新のアルゴリズムの開発を導くのに役立ちます5,50。

ただし、GPT-2の表現と人間の理解との関係は、まだ資格がありません。まず、セマンティック理解の挑戦的で複合概念を経験的定義に制限します。つまり、各ストーリーの最後に提示されたアンケートで評価されるように、被験者が物語を理解する程度です。理解は、科学的な執筆から新聞に至るまで、現在テストされていない新聞に至るまで、非常に多様な条件に及ぶことを認めています。

第二に、私たちの結果は相関のみに基づいています。補足分析では、GPT-2の脳スコアは、注意プロセスによって部分的に説明される可能性があるが、縮小しないことが示唆されています（補足情報H）。しかし、注意、事前知識、ワーキングメモリ能力、言語の複雑さなど、理解に影響を与える要因は、ここでは制御されないため、将来の仕事で明示的に調べて操作する必要があります。特に、作業記憶容量、認知制御、語彙、および被験者の注意の継続的な監視が理解の変動に個別に貢献し、GPT-2と脳の間のリンクを特に説明する方法を評価することは興味深いでしょう。。同様に、個人間の違いの研究は、障害、失読症、自閉症症候群などの理解に関連する特定の認知障害のモデル化にさらに役立つ可能性があります。ただし、このような調査には大量のデータが必要であるため、専用の努力が必要です51。

第三に、GPT-2中層の長距離表現は、連想皮質の理解を特に説明し、浅い層にエンコードされた短距離情報は、低レベルの脳領域の理解を説明していることがわかります。ただし、これらの機能が実際に表すことは、ほとんど不明のままです。以前の研究では、言語変圧器がSyntactic14,52およびセマンティック機能14を明示的に表すことが示されています14。同様に、Manning et al。構文ツリーは、コンテキスト化された単語埋め込みの距離によってエンコードされているように見えることを示しました52。単語の埋め込みの性質を明確にすることは、探求する重要な方向性のままです（例：Syntactic vs. Semantic8,11,53,54。

最後に、代替モデル（補足図S3）よりも非常に有意であり、大幅に優れていますが、GPT-2の脳スコアは比較的低い5,26,35です。この現象は大部分が期待されています。選択バイアスを避けるために、単一の単一ボクセルレベルおよびすべての脳ボクセルにわたって脳マッピングに合わせて評価します。それにもかかわらず、これらの脳スコアはノイズの天井の最大32％に達します（補足情報D、補足図S2）。これは、GPT-2が脳内の言語表現の最良のモデルであるかもしれないが、複雑な物語のものを完全に捉えることからはほど遠いままであることを示しています。

脳、行動、深い網の比較は、もともとビジョン研究で導入されました55。本研究はこのアプローチを強化し、GPT-2と脳の間のリンクを明確にします。具体的には、GPT-2のマッピングが\（\ mathcal {r} = 0.50 \）までの理解と相関することを示します。この結果は有望であり、限られています。一方では、深いネットと脳の類似性が高レベルの認知プロセスに非文書的に関連していることを明らかにします。一方、理解の変動の半分は、このアルゴリズムによって説明されていないままです。

この制限が予想されます。いくつかの研究は、現在の深い言語モデルが理解に不可欠ないくつかの側面をキャプチャできないことを示しています（iii）テキストの要約、ストーリーの生成、質問への回答20,21,22には比較的貧弱なままです。さらに、GPT-2はテキストデータでのみトレーニングされており、実際の相互作用をキャプチャする接地環境にオブジェクトを配置しません18,57。ただし、これらの制限は一時的なものである可能性があります。最新のモデルは、分散型sampling58に対してより堅牢であり、マルチモーダルデータ59,60でトレーニングされているように見えます。

一緒に、これらの要素は、GPT-2のような現代の言語アルゴリズムが、理解の脳と計算署名を解明するための有望な基盤を提供することを示唆しています。その逆もまた、深い言語モデルと脳の類似点と残りの違いを強調することにより、神経科学とAIの相互関連性を強化します。

材料と方法
-----

私たちの分析は、27の物語を聞いている345人の被験者のfMRIを使用して記録された脳信号で構成される「物語」データセット61に依存しています。データセットは公開されており、メソッドは関連するガイドラインと規制に従って実行されました。

### 物語と理解スコア

データセットの27のストーリーの中で、科目が最後に理解アンケートに答えるように求められた7つのストーリーを選択しました。オーディオ刺激の合計で、ストーリーごとに4〜19分（図3）。アンケートは、人間によって評価された複数の選択、充填、または開かれた質問（無料のテキストで回答）でした61。ここでは、元のデータセットで計算された理解度スコアを使用しました。これは、正解の一部または人間の評価の合計であり、0から161の間で拡大します。1つの物語（それぞれに固有の1つの主題の理解）を要約します（物語に固有の、件名）ペア）。



**Figure 3**

[[error]](/articles/s41598-022-20460-9/figures/3)7つの物語のそれぞれについて：被験者の数（n）、被験者間の理解スコアの分布、物語の長さ。

[フルサイズの画像](/articles/s41598-022-20460-9/figures/3)### 脳の活性化

選択された7つの物語を聞いた101人の被験者の脳の活性化は、fMRIを使用して記録されました。元のPaper61で示唆されているように、（主題、物語）のペアは騒々しい録音のために除外され、合計237ペアが生じました。

7つの研究すべてが1.5秒の繰り返し時間（TR）を使用しました。Orginal Paper61に記載されているように、「Merlin」、「Sherlock」、「Slumlord」、「Reach for the Stars」データセットは、20チャンネルのフェイスドアレイヘッドコイルで3T Siemens Magnetom Skyra（ドイツ、ドイツ、ドイツ）で収集されました。次の取得パラメーターを使用します。「grappaを使用して平面加速係数2の勾配エコーエコー平面イメージング（EPI）を使用して、機能的な太字画像をインターリーブ式で取得しました。完全な取得の詳細は、簡単にするためにここにまとめられています：TR/TE = 1500/28 ms、フリップ角= 64度、帯域幅= 1445 Hz/px、面内解像度= 3x3mm、スライス厚\（= 4 \）mm、マトリックスsize = \（64 \ times 64 \）、fov = \（192 \ times 192 \）mm、ほぼ完全な脳覆いとギャップなし、前後位相エンコーディング、妊娠後期正規化、脂肪抑制を伴う27軸スライス。各実行の開始時に、3つのダミースキャンが取得され、スキャナーによって廃棄され、信号の安定化が可能になりました。

「パイマン（PNI）」（Pieman-PNI）「ブロンクスから走る」（ブロンクス）、「私はあなたが黒人だった」（黒）、「レイ・ブラッドベリーを忘れた男」（忘れた）データセットが収集されました。異なる取得パラメーターを使用して、64チャンネルヘッドコイルを備えた同じ3T Siemens Magnetom Prisma。機能画像は、ブリッピングカイピリーニャを使用して3のマルチバンド加速度係数を使用して勾配エコーEPIを使用してインターリーブされた方法で取得しました。、インプレーン解像度= \（2.5 \ times 2.5 \）mm、スライス厚2.5 mm、マトリックスサイズ= \（96 \ times 96 \）、fov = \（240 \ times 240 \）mm、48軸スライスと完全な完全な軸方向スライス脳のカバレッジとギャップなし、前後位相エンコード、妊娠中の正規化、脂肪抑制、3回のダミースキャン。」

### GPT-2アクティベーション

GPT-21は、何百万もの例（ウィキペディアのテキストなど）を与えられた、その以前のコンテキスト（後続の単語にアクセスできない）を考慮して単語を予測するように訓練された高性能の神経言語モデルです。非コンテキストワードの埋め込み（語彙ごとに単一のベクトルを出力するルックアップテーブル）1に積み重ねられた複数の変圧器モジュール（それぞれが「レイヤー」と呼ばれる）で構成されています。各レイヤーkは、w単語のシーケンスを入力として採用し、レイヤーk（\（d = \、768 \）の「アクティベーション」と呼ばれるコンテキストベクトル（w、d）のコンテキストベクトル（w、d）を出力する非線形システムとして見ることができます。））。中間層は、入力および出力層よりも構文情報とセマンティック情報をよりよくエンコードすることが示され、脳の活動へのより良いマッピング5,7。ここでは、GPT-2の8番目の層が脳の活動を最もよく予測することを示します。したがって、分析のためにGPT-2の8層を選択します。私たちの結論は、GPT-2の他の中間から深い層（\（6^{\ text {th}} \）から\（12^{\ text {th}} \）レイヤー）から変化しません。

実際には、物語の転写産物がフォーマットされました（「 - 」などの特別な句読点を置き換え、ドットで「？」の重複したマークを置き換えます）、GPT-2トーナイザーを使用してトークン化し、Huggingface63が提供するGPT-2前処理モデルに入力しました。各トークンの表現は、1024トークンのスライドコンテキストウィンドウを使用して個別に計算されます。たとえば、ストーリーの3番目のトークンの表現を計算するために、GPT-2を3番目、2番目、1番目のトークンに入力し、3番目のトークンに対応するアクティベーションを抽出します。同様に、\（1500^{\ text {th}} \）トークンのアクティブ化を計算するために、モデルを1500という単語と1023ワードで入力します。全体として、すべての単語\（w\_k \）のアクティブ化は、モデルを単語\（w\_k \）と1023の前のトークン（せいぜい）で入力し、\（w\_k \）に対応するアクティベーションを抽出することによって計算されます。この手順では、ストーリー内のトークンの数とモデルの次元をwで、サイズ（w、d）のアクティブ化のベクトルをもたらします。言葉よりもfMRIスキャンが少ない。したがって、連続したfMRI測定間の活性化ベクトルを合計して、測定ごとにサイズdの1つのベクトルを取得します。fMRI測定値とGPT-2ベクターを時間の経過とともに一致させるために、fMRI DataSet61で提供される音声からテキスト対応を使用しました。

### GPT-2と脳の間の線形マッピング

各（主題、物語）ペアについて、（i）物語によって誘発されたfMRIの活性化と（ii）同じ物語によって誘発されたGPT-2（レイヤー8）の活性化の間のマッピングを測定します。この目的のために、GPT-2の活性化を入力としてfMRIスキャンを予測するために、線形の時空モデルが列車セットに適合されます。次に、マッピングは、予測されたfMRIスキャンと実際のfMRIスキャンとの間のピアソン相関を計算して評価されます。

$$\begin{aligned} {\mathcal {M}}^{(s, w)} : I \mapsto \mathcal {L} \bigg ( f \circ g(X^{(w)})\_{i \in I}, (Y^{(s, w)}\_i)\_{i \in I} \bigg ) \end{aligned}$$
 (1)
 \（f \ circ g \）を使用して、適合推定器（g：時間およびf：空間マッピング）、\（\ mathcal {l} \）ピアソンの相関、\（x^{（w）} \）gptのアクティブ化-2および\（y^{（s、w）} \）sのfMRIスキャンは、両方とも物語wによって誘発されました。

実際には、fはa \（\ ell \_2 \） - scikit-learn実装に続いて、ペナルティ化された線形回帰64です。正規化パラメーターは、列車セットのネストされたクロス検証を使用して、各ボクセルに対して個別に選択されます。具体的には、\（10^{-1} \）と\（10^8 \（10^8 \）の間にログ間隔が10の可能な10の可能な正則化パラメーターを使用して、組み込みのleave-one-sample-out Cross-validationを備えたScikit-LearnのRidgecv推定器を使用します。）、各ボクセルに対して独立して選択されている1つのハイパーパラメーター。Gは5つの遅延を備えた有限インパルス応答（FIR）モデルであり、各遅延は2つのTRの間に表示される単語とGPT-2入力のアクティブ化を合計します。各（主題、物語）ペアについて、Scikit-Learnの交差検証を使用して、対応するfMRI時系列を5つの隣接するチャンクに分割します。手順は、5つの列車（fMRIスキャンの80％）と分離テストの折り目（fMRIスキャンの20％）で繰り返されます。ピアソンの相関は、テスト折り目で平均化され、1つのスコア（サブジェクト、ナラティブ）ペアを取得します。図1aの\（\ mathcal {m}（x）\）と記載されているこのスコアは、1つの物語によって誘発された1つの被験者のアクティベーション空間xと1つの被験者の脳の間のマッピングを測定します。

### 音韻的特徴

低レベルの音声処理を説明するために、fMRI脳記録yと音韻特徴xの間のアライメント（式（1））を計算しましたx：単語レート（d = \、1 \）、の数、fmriスキャンあたりの単語）、音素レート（\（d = \、1 \）、fMRIスキャンあたりの音素数）、および刺激内の単語の音素、ストレス、トーンの連結（カテゴリの特徴、\（d）= \、117 \））。後者の音韻機能は、元のデータセットで提供され、gentle65を使用して計算されます。117の寸法は、音声カテゴリ、ストレス、トーンの組み合わせです。コーパスで40個の英語の音素と4つの可能なトーンを使用して、40 x 4 = 160のカテゴリになります。ここでは、いくつかのカテゴリが発音されることはありません。これらのカテゴリを無視すると、これにより117のカテゴリ、したがって1ホットのエンコード後の117の寸法が生じます。

### ボクセルレベルおよびROIレベル分析

すべての第1レベルの分析は、ボクセルレベルで実行されます（マッピングスコアの計算\（\ mathcal {m} \）eq。（1）、図1の青）。次に、各脳領域内のこれらの効果（1）（図1b、e、f、g）または（2）のいずれか（図1cおよびd）のいずれか（1）のいずれかのいずれかのいずれかを平均します。これらの平均値から、理解との相関を計算します（図1の赤）。このアプローチは、複数の比較の効果の局在と統計的修正を軽減します。

### 意義

有意性は、（i）2番目のウィルコクソンテスト（両側）を使用して、主題のナラティブペア全体で評価され、マッピング（ペアごとに1つの値）がゼロ（図1B）とは大きく異なるかどうかをテストするか（ii）SCIPY28によって提供される第1レベルのピアソンP値を使用することにより（図1D – G）。図1b、e、f、p値は、誤検出率（ベンジャミン/ホックバーグ）66を使用して、多重比較（2 \（\ times \）142 ROI）に対して修正されました。




データの可用性
-------


ナラティブデータセット61は、openneuro（https://openneuro.org/datasets/ds002345/versions/1.1.4）およびhttp://datasets.datalad.org/？dir=/labs/hasson//で公開されています。物語）。


参照
--

1. ラドフォード、A。etal。言語モデルは、教師のないマルチタスク学習者です。Openai Blog 1（8）、9（2019）。
 Google Scholar
2. Devlin、J.、Chang、M。W.、Lee、K。、＆Toutanova、K。Bert：言語理解のための深い双方向変圧器の事前訓練。Arxiv：1810.04805 [CS]、（2019）。
3. Yang、Z.、Dai、Z.、Yang、Y.、Carbonell、J.、Salakhutdinov、R。R.、＆Le、Q。Xlnet：言語理解のための一般化された自己回帰事前削除。arxiv：1906.08237 [cs]、（2020）。
4. Caucheteux、C.、Gramfort、A。、およびKing、J。R。脳活動のモデルベースの分析は、305人の被験者の言語の階層を明らかにしています。自然言語処理における経験的方法に関するEMNLP 2021会議（2021a）。
5. Toneva、M。＆Wehbe、L。自然言語処理（脳内）を使用した自然言語処理（機械内）の解釈と改善。Arxiv：1905.11833 [CS、Q-Bio]、（2019）。
6. Schrimpf、M。etal。言語の神経アーキテクチャ：統合モデリングは、予測処理に収束します。Proc。natl。アカデミー。SCI。118（45）、E2105646118。https://doi.org/10.1073/pnas.2105646118（2021）.Article
 CAS
 PubMed
 PubMed Central
 
 Google Scholar
7. Caucheteux、C。＆King、J.-R。脳とアルゴリズムは、自然言語処理に部分的に収束します。コミューン。Biol。5（1）、1–10。https://doi.org/10.1038/S42003-022-03036-1（2022）.Article
 
 Google Scholar
8. Caucheteux、C.、Gramfort、A。、およびKing、J.-R。深いネットワークを備えた脳の構文とセマンティクスを解き放ちます。機械学習に関する国際会議、1336–1348。PMLR、（2021b）。
9. Hale、J。Fontelli、L.、Li、J。Parlier、C。＆Brrenan、J。Neuro-Computフランス語モデルの言語プロム。年。牧師ラグ、（2021）。
10. アンダーソン、A。J。et al。深い人工ニューラルネットワークは、命題の文レベルの意味をコードする分散皮質ネットワークを明らかにしています。J. Neurosci。41（18）、4100–4119。https://doi.org/10.1523/jneurosci.1152-20.2021（2021）.Article
 CAS
 PubMed
 PubMed Central
 
 Google Scholar
11. Jingyuan、S.、Shaonan、W.、Jiajun、Z。＆Chengqing、Z。分散文の表現による神経エンコードと解読。IEEEトランス。ニューラルネット。学ぶ。syst。32（2）、589–603。https://doi.org/10.1109/tnnls.2020.3027595（2021）.Article
 
 Google Scholar
12. ゴールドスタイン、A。etal。今後の考え方：人間と機械の言語のキーストーンとしての文脈での予測。biorxivhttps：//doi.org/10.1101/2020.12.02.403477（2021）.Article
 PubMed
 PubMed Central
 
 Google Scholar
13. Nie、Y.、Williams、A.、Dinan、E.、Bansal、M.、Weston、J。、＆Kiela、D。Anversarial Nli：自然言語理解のための新しいベンチマーク。arxiv preprintarxiv：1910.14599、（2019）。
14. Lakretz、Y.、Desbordes、T.、King、J.-R。Crabbé、B.、Oquab、M。＆Dehaene、S。arxiv：2101.02258 [cs]、（2021）。
15. Hupkes、D.、Dankers、V.、Mul、M。＆Bruni、E。構成性分解：ニューラルネットワークはどのように一般化しますか？J. Artif。インテル。res。67、757–795（2020）.Article
 MathScinet
 
 Google Scholar
16. Lake、B。M.＆Murphy、G。L. Word Meaning Mind and Machines。Arxiv：2008.01766 [CS]、（2021）。
17. Linzen、T。＆Baroni、M。深い学習の構文構造。アン。言語学者牧師。7、195–212（2021）.Article
 
 Google Scholar
18. McClelland、J。L.、Hill、F.、Rudolph、M.、Baldridge、J。＆Schütze、H。Proc。natl。アカデミー。SCI。117（42）、25966–25974。https://doi.org/10.1073/pnas.1910416117（2020）.Article
 広告
 CAS
 PubMed
 PubMed Central
 
 Google Scholar
19. ゲイリー、M。GPT-2と知性の性質。勾配。https://thegradient.pub/gpt2-and-the-nature of-intelligence/（2020）。
20. Holtzman、A.、Buys、J.、Du、L.、Forbes、M。＆Choi、Y。神経テキストの変性の奇妙な事例。Arxiv：1904.09751 [CS]、（2020）。
21. ワイズマン、S。、シーバー、S。M。＆ラッシュ、A。M。データからドキュメントの世代の課題。Arxiv：1707.08052 [CS]、（2017）。
22. Thakur、N.、Reimers、N.、Ruckle、A.、Srivastava、A。、＆Gurevych、I。Beir：情報検索モデルのゼロショット評価のための異種のベンチマーク。arxiv：2104.08663 [cs]、（2021）。
23. Raffel、C.、Shazeer、N.、Roberts、A.、Lee、K.、Narang、S.、Matena、M.、Zhou、Y.、Li、W。＆Liu、P.J。統一されたテキストからテキスト変圧器。arxiv：1910.10683 [cs、stat]、（2020）。
24. Krishna、K.、Roy、A。＆Iyyer、M。長い形式の質問応答の進歩へのハードル。arxiv：2103.06332 [cs]、（2021）。
25. ヤミンズ、D。L。K. et al。パフォーマンスが最適化された階層モデルは、より高い視覚皮質の神経反応を予測します。Proc。natl。アカデミー。SCI。111（23）、8619–8624。https://doi.org/10.1073/pnas.1403112111（2014）.Article
 広告
 CAS
 PubMed
 PubMed Central
 
 Google Scholar
26. Huth、A。G.、De Heer、W。A.、Griffiths、T。L.、Theunissen、F。E.＆Gallant、J。L. Natural Speechは、人間の脳皮質をタイルするセマンティックマップを明らかにします。Nature 532（7600）、453–458。https://doi.org/10.1038/Nature17637（2016）.Article
 広告
 PubMed
 PubMed Central
 
 Google Scholar
27. Destroweux、C.、Fischl、B.、Dale、A。＆Halgren、E。標準的な解剖学的命名法を使用したヒト皮質GyriおよびSulciの自動分割。ニューロイメージ53（1）、1–15。https://doi.org/10.1016/j.neuroimage.2010.06.010（2010）.Article
 PubMed
 
 Google Scholar
28. Virtanen、P。etal。Scipy 1.0の寄稿者。Scipy 1.0：Pythonの科学コンピューティングの基本的なアルゴリズム。ナット。方法17、261–272。https://doi.org/10.1038/S41592-019-0686-2（2020）.Article
 CAS
 PubMed
 PubMed Central
 
 Google Scholar
29. Jain、S。＆Huth、A。G. fMRIのモデルをコードする言語エンコードにコンテキストを組み込む。Preprint、Neuroscience（2018）。
30. Schrimpf、M.、Kubilius、J.、Hong、H.、Majaj、N.J.、Rajalingham、R.、Issa、E.B.、Kar、K.、Bashivan、P.、Prescott-Roy、J.、Geiger、F。＆Schmidt、K.、Brain-Score：オブジェクト認識のための人工ニューラルネットワークは、最も脳のようなものですか？Preprint、Neuroscience（2018）。
31. Mesgarani、N。＆Chang、E。F.マルチトーカーの音声認識における出席者スピーカーの選択的皮質表現。Nature 485（7397）、233–236。https://doi.org/10.1038/Nature11020（2012）.Article
 広告
 CAS
 PubMed
 
 Google Scholar
32. Cohen、L.、Salondy、P.、Pallier、C。＆Dehaene、S。Cortex 138、212–227（2021）.Article
 
 Google Scholar
33. Lerner、Y.、Honey、C。J.、Silbert、L。J.＆Hasson、U。ナレーションされたストーリーを使用した時間的受容窓の階層の地形マッピング。J. Neurosci。31（8）、2906–2915。https://doi.org/10.1523/jneurosci.3684-10.2011（2011）.Article
 CAS
 PubMed
 PubMed Central
 
 Google Scholar
34. Pallier、C.、Devauchelle、A.-D。＆Dehaene、S。文の構成構造の皮質表現。Proc。natl。アカデミー。SCI。108（6）、2522–2527。https://doi.org/10.1073/pnas.1018711108（2011）.Article
 広告
 PubMed
 PubMed Central
 
 Google Scholar
35. Fedorenko、E。et al。文の意味の構築の神経相関。Proc。natl。アカデミー。SCI。usahttps：//doi.org/10.1073/pnas.1612132113（2016）.Article
 PubMed
 PubMed Central
 
 Google Scholar
36. Friederici、A。D.言語処理の脳の基礎：構造から機能まで。フィジオール。Rev. 91（4）、1357–1392。https://doi.org/10.1152/physrev.00006.2011（2011）.Article
 PubMed
 
 Google Scholar
37. Hickok、G。＆Poeppel、D。音声処理の皮質組織。ナット。牧師神経。8（5）、393–402。https://doi.org/10.1038/NRN2113（2007）.Article
 CAS
 PubMed
 
 Google Scholar
38. Hagoort、P.、Baggio、G。＆Wlllems、R。M ..セマンティック統一。認知神経科学、第4版、819–835（マサチューセッツ工科大学、マサチューセッツ州ケンブリッジ、2009年）。
39. Hagoort、P。MUC（記憶、統合、制御）およびそれ以降。フロント。サイコル。4、416（2013）.Article
 
 Google Scholar
40. Hagoort、P。＆Indefrey、P。単一の単語を超えた言語の神経生物学。アン。牧師神経。37、347–362。https://doi.org/10.1146/annurev-neuro-071013-013847（2014）.Article
 CAS
 PubMed
 
 Google Scholar
41. Bornkessel-Schlesewsky、I。＆Schlesewsky、M。サイコル。Rev. 113、787–821。https://doi.org/10.1037/0033-295X.113.4.787（2006）.Article
 
 Google Scholar
42. Bornkessel-Schlesewsky、I。＆Schlesewsky、M。時間、空間、機能の調整：文の理解の新しい背腹河川モデル。脳のラング。125（1）、60–76。https://doi.org/10.1016/j.bandl.2013.01.010（2013）.Article
 PubMed
 
 Google Scholar
43. ウルマン、M。T。言語に関する神経認知的視点：宣言/手続きモデル。ナット。牧師神経。2（10）、717–726。https://doi.org/10.1038/35094573（2001）.Article
 CAS
 PubMed
 
 Google Scholar
44. Lu、Q.、Hasson、U。＆Norman、K。A.エピソード記憶を取得してエンコードする時期のニューラルネットワークモデル。Elife 11、E74445。https://doi.org/10.7554/elife.74445（2022）.Article
 CAS
 PubMed
 PubMed Central
 
 Google Scholar
45. Dehghani、M。et al。言語間のストーリーの意味の神経表現の解読：神経表現の解読。ハム。脳マップ。38（12）、6096–6106。https://doi.org/10.1002/hbm.23814（2017）.Article
 PubMed
 PubMed Central
 
 Google Scholar
46. Broderick、M。P.、Zuk、N。J.、Anderson、A。J.＆Lalor E. C.プリプリント、神経科学（2020）。
47. Broderick、M。P.、Anderson、A。J.、Di Liberto、G。M.、Crosse、M。J.＆Lalor、E。C.物語のスピーチ。Curr。Biol。28（5）、803–809。https://doi.org/10.1016/j.cub.2018.01.080（2018）.Article
 CAS
 PubMed
 
 Google Scholar
48. Sabri、M。etal。音声認識における注意と言語の相互作用。Neuroimage 39（3）、1444–1456。https://doi.org/10.1016/j.neuroimage.2007.09.052（2008）.Article
 PubMed
 
 Google Scholar
49. Kok、P.、Jehee、J。F。M.＆De Lange、F。P。ニューロン75（2）、265–270。https://doi.org/10.1016/j.neuron.2012.04.034（2012）.Article
 CAS
 PubMed
 
 Google Scholar
50. Caucheteux、C.、Gramfort、A。＆King、J.-R。脳とアルゴリズムの長距離および階層的な言語予測。arxiv：2111.14232 [cs、q-bio]、（2021）。
51. スコット、M。etal。再現可能な脳全体の関連研究には、何千人もの個人が必要です。Naturehttps：//doi.org/10.1038/S41586-022-04492-9（2022）.Article
 PubMed
 PubMed Central
 
 Google Scholar
52. Manning、C。D.、Clark、K.、Hewitt、J.、Khandelwal、U。＆Levy、O。Self-Supervisionによって訓練された人工ニューラルネットワークの緊急言語構造。Proc。natl。アカデミー。Sci.https：//doi.org/10.1073/pnas.1907367117（2020）.Article
 PubMed
 PubMed Central
 
 Google Scholar
53. Gauthier、J。＆Levy、R。言語の人工的および人間の神経表現のリンク。自然言語加工における経験的方法に関する2019年の会議の議事録および第9回自然言語加工に関する共同会議（EMNLP-IJCNLP）、529–539、香港、中国、（2019）。計算言語学の協会。https://doi.org/10.18653/V1/D19-1050。
54. Reddy、A。J。＆Wehbe、L。人間の脳の構文表現：努力ベースのメトリックを超えて。プリプリント、神経科学（2020）。
55. Yamins、D。L。K.＆Dicarlo、J。J。目標駆動型の深い学習モデルを使用して、感覚皮質を理解します。ナット。神経筋。19（3）、356–365。https://doi.org/10.1038/NN.4244（2016）.Article
 CAS
 PubMed
 
 Google Scholar
56. Baroni、M。現代の人工ニューラルネットワークにおける言語の一般化と構成性。哲学。トランス。R. Soc。B Biol。SCI。375（1791）、20190307。https：//doi.org/10.1098/rstb.2019.0307（2020）.Article
 
 Google Scholar
57. Bisk、Y。、Holtzman、A.、Thomason、J.、Andreas、J.、Bengio、Y.、Chai、J.、Lapata、M.、Lazarou、A.、May、J.、Nisnevich、A。Pinto 、N。＆TURIAN、J。経験の根拠の言語。arxiv：2004.10151 [cs]、（2020）。
58. ブラウン、T。B.、マン、B。、ライダー、N。、サブビア、M。、カプラン、J。、ダリワル、P。、ニーラカンタン、A。、シャム、P.、サストリー、G。、アステル、A。、アガルワル、S。、Herbert-Voss、A.、Krueger、G.、Henighan、T.、Child、R.、Ramesh、A.、Ziegler、D.M.、Wu、J.、Winter、C.、Hesse、C.、Chen、M.、Sigler、E.、Litwin、M.、Gray、S.、Chess、B.、Clark、J.、Berner、C.、McCandlish、S.、Radford、A.、Sutskever、I。＆Amodei、D。言語モデルは、少ないショット学習者です。arxiv：2005.14165 [cs]、（2020）。
59. Radford、A.、Kim、J.W.、Hallacy、C.、Ramesh、A.、Goh、G.、Agarwal、S.、Sastry、G.、Askell、A.、Mishkin、P.、Clark、J J。、Krueger、G。＆Sutskever、I。自然言語監督からの移転可能な視覚モデルの学習。arxiv：2103.00020 [cs]、（2021）。
60. Ramesh、A.、Pavlov、M.、Goh、G.、Gray、S.、Voss、C.、Radford、A.、Chen、M。＆Sutskever、I。Zero-Shot Text-to-Imageの生成。arxiv：2102.12092 [cs]、（2021）。
61. Nastase、S。A.、Liu、Y.-F。、Hillman、H.、Zadbood、A.、Hasenfratz、L.、Keshavarzian、N.、Chen、J.、Honey、C。J.、Yeshurun、。、Regev、M。 M.、Chang、C。H. C.、Baldassano、C.、Lotsky、O.、Simony、E.、Chow、M.、M.、Leong、Y.C.、Brooks、P。P.、Micciche、E.、Choe、G.、Goldstein、 A.、Vanderwal、T.、Halchenko、Y.、O、Norman、K。＆Hasson、U。物語：自然主義的言語理解のモデルを評価するFMRIデータ。プリプリント、神経科学（2020）。
62. Jawahar、G.、Sagot、B。＆Seddah、D。バートは言語の構造について何を学びますか？第57回計算言語学会協会、3651–3657、フィレンツェ、イタリア、（2019）の議事録。計算言語学の協会。https://doi.org/10.18653/v1/p19-1356。
63. Wolf、T.、Debut、L.、Sanh、V.、Chaumond、J.、Delangue、C.、Moi、A.、Cistac、P.、Rault、T.、Louf、R.、Funtowicz、M.、Davison、J.、Shleifer、S.、Von Platen、P.、Ma、C.、Jernite、Y.、Plu、J.、Xu、C.、Scao、T。L.、Gugger、S.、Drame、M.、Lhoest、Q。＆Rush、A。M. Transformers：最先端の自然言語処理。自然言語処理における経験的方法に関する2020年の会議の議事録：システムデモンストレーション、38〜45、オンライン（2020）。計算言語学の協会。
64. Pedregosa、F。etal。Scikit-Learn：Pythonでの機械学習。J.マッハ。学ぶ。res。12、2825–2830（2011）.Mathscinet
 数学
 
 Google Scholar
65. 優しい。https://lowerquality.com/gentle/。
66. Gramfort、A。etal。MNE-Pythonを使用したMEGおよびEEGデータ分析。フロント。神経筋。7（267）、1–13。https://doi.org/10.3389/fnins.2013.00267（2013）.Article
 
 Google Scholar
67. Seabold、S。＆Perktold、J。Statsmodels：Pythonを使用した経済的および統計的モデリング。9th Python in Science Conference、（2010）。
68. Nunez-Elizalde、A。O.、Huth、A。G.＆Gallant、J。L. VoxelWiseエンコーディングモデルは、非球体多変量正常プライアーを備えています。Neuroimage 197、482–492。https://doi.org/10.1016/j.neuroimage.2019.04.012（2019）.Article
 PubMed
 
 Google Scholar

参照をダウンロードします

謝辞
--

物語のデータセットに関する追加情報を提供してくれたSam NastaseとCollaboratorsに感謝します。この作業は、PSLでの仕事のためにJRKのANR-17-Eure-0017、Fyssen Foundation、およびBettencourt Foundationによってサポートされていました。

著者情報
----

### 著者と所属

1. メタAI Research、パリ、フランセチャルロットカウチテックス、ジャンレミキング
2. 大学パリ - サクレイ、インリア、CEA、パレソー、フランセチャルロットカウチェツ＆アレクサンドルグラムフォート
3. エコール・ノーマル・スペリエール、PSL大学、CNRS、パリ、フランスジアン・レミ・キング

Authors1. Charlotte caucheteuxview著者の出版物もこの著者を検索することができます
 PubMed Google Scholar
2. alexandre gramfortview著者の出版物もこの著者を検索することができます
 PubMed Google Scholar
3. jean-rémikingview著者の出版物もこの著者を検索することができます
 PubMed Google Scholar
### 貢献

3人の著者全員が実験と研究の質問を設計しました。C.C.実験を開始し、図を準備し、結果を分析しました。3人の著者全員が調査結果を解釈し、論文を書きました。

### 対応する著者

に対応
 シャーロット・コーシュテックス。

倫理宣言
----


### 競合する利益


著者は、競合する利益はないと宣言しています。


追加情報
----

### 出版社のメモ

スプリンガーの自然は、公開された地図と制度上の所属における管轄権の主張に関して中立のままです。

補足情報
----

### 補足情報。

権利と許可
-----


オープンアクセスこの記事は、元の著者とソースに適切なクレジットを提供する限り、任意の媒体または形式での使用、共有、適応、配布、および複製を許可するCreative Commons Attribution 4.0 Internationalライセンスの下でライセンスされています。Creative Commonsライセンスへのリンクを提供し、変更が行われたかどうかを示します。この記事の画像またはその他のサードパーティの資料は、特に資料のクレジットラインに特徴を示さない限り、記事のCreative Commonsライセンスに含まれています。記事のCreative Commonsライセンスに資料が含まれておらず、目的の使用が法定規制によって許可されていない場合、または許可された使用を超えている場合、著作権所有者から直接許可を取得する必要があります。このライセンスのコピーを表示するには、http：//creativecommons.org/licenses/by/4.0/にアクセスしてください。


再版と許可

この記事について
--------

[[error]](https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-022-20460-9)### この記事を引用してください

Caucheteux、C.、Gramfort、A。＆King、Jr。ディープ言語アルゴリズムは、脳の活動からの意味的理解を予測します。
 Sci Rep 12、16327（2022）。https://doi.org/10.1038/S41598-022-20460-9

引用をダウンロードしてください

* 受信：2021年11月17日
* 受け入れ：2022年9月13日
* 公開：2022年9月29日
* doi：https：//doi.org/10.1038/S41598-022-20460-9

### この記事を共有してください

次のリンクを共有する人は誰でもこのコンテンツを読むことができます。

Get shareable link申し訳ありませんが、この記事では現在共有可能なリンクは利用できません。

[error]

Copy to clipboardSpringer Nature Sharedit Content-Sharingイニシアチブによって提供されます



コメント
----

コメントを送信することにより、私たちの条件とコミュニティのガイドラインを順守することに同意します。虐待的なものを見つけたり、条件やガイドラインに準拠していない場合は、不適切であるとフラグを立ててください。












[PDFをダウンロードします](/articles/s41598-022-20460-9.pdf)




関連するコンテンツ
---------




コレクション


### ジャーナルトップ100-2022






コレクション


### 心理学のトップ100 -2022













広告




[[error]](//pubads.g.doubleclick.net/gampad/jump?iu=/285/scientific_reports/article&sz=300x250&c=647577353&t=pos%3Dright%26type%3Darticle%26artid%3Ds41598-022-20460-9%26doi%3D10.1038/s41598-022-20460-9%26subjmeta%3D117,1594,2649,378,631,639,705%26kwrd%3DComputer+science,Language)














コンテンツを探索します
-----------


* 研究記事
* ニュースとコメント
* コレクション
* 科目


* フェースブックでフォローして
* Twitterでフォローします
* アラートにサインアップします
* RSSフィード






ジャーナルについて
---------


* オープンアクセス料金と資金
* 科学的報告について
* 接触
* ジャーナルポリシー
* 論文の呼びかけ
* 審判へのガイド
* 編集者の選択
* ジャーナルのハイライト






私たちと一緒に公開してください
---------------


* 著者のために
* 言語編集サービス
* 原稿を提出します






検索
--



Search articles by subject, keyword or author






Show results from

All journals
This journal



Search





[高度な検索](/search/advanced)

### クイックリンク


* 主題ごとに記事を探索します
* 仕事を見つける
* 著者へのガイド
* 編集ポリシー









科学レポート（SCI担当者）
 

ISSN 2045-2322（オンライン）







Nature.comサイトマップ
----------------





### 自然ポートフォリオについて


* 私たちについて
* プレスリリース
* プレスオフィス
* お問い合わせ




### コンテンツを発見します


* ジャーナルA-Z
* 主題による記事
* protocols.io[error]
* 自然指数




### 公開ポリシー


* 自然ポートフォリオポリシー
* オープンアクセス




### 著者および研究者サービス


* 再版と許可
* 研究データ
* 言語編集
* 科学編集
* 自然のマスタークラス
* 研究ソリューション




### 図書館と機関


* 司書サービスとツール
* 司書ポータル
* オープンリサーチ
* 図書館にお勧めします




### 広告とパートナーシップ


* 広告
* パートナーシップとサービス
* メディアキット
* ブランド
 コンテンツ




### 専門能力開発


* 自然のキャリア
* 自然
 会議




### 地域のウェブサイト


* 自然アフリカ
* 自然中国
* 自然インド
* 自然イタリア
* 自然日本
* 自然中東






* プライバシー
 ポリシー
* 使用
 クッキーの
* あなたのプライバシーの選択/Cookieの管理
* 法律上の
 知らせ
* アクセシビリティ
 声明
* 利用規約
* あなたの米国のプライバシー権





[[error]](https://www.springernature.com/)
©2024 Springer Nature Limited





xml version="1.0" encoding="UTF-8"?








Close banner






Close





![Nature Briefing AI and Robotics](/static/images/logos/nature-briefing-ai-and-robotics-logo-51b3cf6c52.svg)


Nature Briefing：AI and Robotics Newsletterにサインアップしてください。AIおよびRobotics Researchで重要なことは、毎週受信トレイに無料です。











Email address



Sign up



I agree my information will be processed in accordance with the *Nature* and Springer Nature Limited [プライバシーポリシー](https://www.nature.com/info/privacy).










Close banner






Close



Get the most important science stories of the day, free in your inbox.
[自然ブリーフィングにサインアップ：AIとRobotics](/briefing/ai-and-robotics/?brieferEntryPoint=AIAndRoboticsBriefingBanner)




![](https://verify.nature.com/verify/nature.png)




![](/s62jn4ig/article/s41598-022-20460-9)




https://www.nature.com/articles/s41598-022-20460-9